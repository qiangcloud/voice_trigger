{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语音唤醒（用Spectrogram信号）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路:在PART1和PART2的基础上将建立自定义的语音唤醒"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集：http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
    "\n",
    "墙虽然挡住了google，但是可以直接下载这个数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import sklearn as sk\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import random\n",
    "import pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音频文件采集\n",
    "使用自制小工具：Customized_command_recorder.py\n",
    "小工具除了录音功能以外，主要是为了方便将音频信号前后的静音信号滤除，避免音频裁剪的时候把音频信号裁掉。\n",
    "\n",
    "采集声音“围棋”，建立文件夹“weiqi”放置在“speech_commands_v0.01”文件夹下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('speech_commands_v0.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('speech_commands_v0.01/bed'),\n",
       " WindowsPath('speech_commands_v0.01/bird'),\n",
       " WindowsPath('speech_commands_v0.01/cat'),\n",
       " WindowsPath('speech_commands_v0.01/dog'),\n",
       " WindowsPath('speech_commands_v0.01/down'),\n",
       " WindowsPath('speech_commands_v0.01/eight'),\n",
       " WindowsPath('speech_commands_v0.01/five'),\n",
       " WindowsPath('speech_commands_v0.01/four'),\n",
       " WindowsPath('speech_commands_v0.01/go'),\n",
       " WindowsPath('speech_commands_v0.01/happy'),\n",
       " WindowsPath('speech_commands_v0.01/house'),\n",
       " WindowsPath('speech_commands_v0.01/left'),\n",
       " WindowsPath('speech_commands_v0.01/marvin'),\n",
       " WindowsPath('speech_commands_v0.01/nine'),\n",
       " WindowsPath('speech_commands_v0.01/no'),\n",
       " WindowsPath('speech_commands_v0.01/off'),\n",
       " WindowsPath('speech_commands_v0.01/on'),\n",
       " WindowsPath('speech_commands_v0.01/one'),\n",
       " WindowsPath('speech_commands_v0.01/right'),\n",
       " WindowsPath('speech_commands_v0.01/seven'),\n",
       " WindowsPath('speech_commands_v0.01/sheila'),\n",
       " WindowsPath('speech_commands_v0.01/silence'),\n",
       " WindowsPath('speech_commands_v0.01/six'),\n",
       " WindowsPath('speech_commands_v0.01/stop'),\n",
       " WindowsPath('speech_commands_v0.01/three'),\n",
       " WindowsPath('speech_commands_v0.01/tree'),\n",
       " WindowsPath('speech_commands_v0.01/two'),\n",
       " WindowsPath('speech_commands_v0.01/up'),\n",
       " WindowsPath('speech_commands_v0.01/weiqi'),\n",
       " WindowsPath('speech_commands_v0.01/wow'),\n",
       " WindowsPath('speech_commands_v0.01/yes'),\n",
       " WindowsPath('speech_commands_v0.01/zero'),\n",
       " WindowsPath('speech_commands_v0.01/_background_noise_')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in data_dir.iterdir() if x.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'down',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'four',\n",
       " 'go',\n",
       " 'happy',\n",
       " 'house',\n",
       " 'left',\n",
       " 'marvin',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'right',\n",
       " 'seven',\n",
       " 'sheila',\n",
       " 'silence',\n",
       " 'six',\n",
       " 'stop',\n",
       " 'three',\n",
       " 'tree',\n",
       " 'two',\n",
       " 'up',\n",
       " 'weiqi',\n",
       " 'wow',\n",
       " 'yes',\n",
       " 'zero',\n",
       " '_background_noise_']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "onlydirs = [d for d in listdir(data_dir) if isdir(join(data_dir, d))]\n",
    "onlydirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onlydirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create silence audio\n",
    "创建一个silence文件夹，并将_background_noise_文件夹中的背景噪声文件进行切割生成1秒的噪声文件\n",
    "\n",
    "这一步在part2已经完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩展需要识别的唤醒词\n",
    "\n",
    "将唤醒词与噪声数据进行混音以扩展测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weiqi_wav = [f for f in os.listdir(join(data_dir, 'weiqi')) if f.endswith('.wav')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-02-21_113830_trim.wav',\n",
       " '2021-02-21_113830_trim_mid.wav',\n",
       " '2021-02-21_113830_vad_0.wav',\n",
       " '2021-02-21_113842_trim.wav',\n",
       " '2021-02-21_113842_trim_mid.wav',\n",
       " '2021-02-21_113842_vad_0.wav',\n",
       " '2021-02-21_114009.wav',\n",
       " '2021-02-21_114009_trim.wav',\n",
       " '2021-02-21_114009_trim_mid.wav',\n",
       " '2021-02-21_114139.wav',\n",
       " '2021-02-21_114139_trim.wav',\n",
       " '2021-02-21_114139_trim_mid.wav',\n",
       " '2021-02-21_114150_trim.wav',\n",
       " '2021-02-21_114150_trim_mid.wav',\n",
       " '2021-02-21_114150_vad_0.wav',\n",
       " '2021-02-21_114239_trim.wav',\n",
       " '2021-02-21_114239_trim_mid.wav',\n",
       " '2021-02-21_114239_vad_0.wav']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weiqi_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "weiqi_audiosegment = []\n",
    "\n",
    "for wav_name in weiqi_wav : \n",
    "    samples = AudioSegment.from_wav(join(join(data_dir,'weiqi'),wav_name))\n",
    "    weiqi_audiosegment.append(samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x20ea6883550>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6883970>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6883880>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6883730>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea68834c0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871100>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871430>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea68718b0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871250>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871dc0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871ee0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20e9b5d6d60>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea68835b0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871b50>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871400>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871760>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871ac0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6871220>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weiqi_audiosegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = [f for f in os.listdir(join(data_dir, '_background_noise_')) if f.endswith('.wav')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doing_the_dishes.wav',\n",
       " 'dude_miaowing.wav',\n",
       " 'exercise_bike.wav',\n",
       " 'pink_noise.wav',\n",
       " 'running_tap.wav',\n",
       " 'white_noise.wav']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_noise = []\n",
    "\n",
    "for wav_name in background : \n",
    "    samples = AudioSegment.from_wav(join(join(data_dir,'_background_noise_'),wav_name))\n",
    "    background_noise.append(samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x20ea657ab20>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea60c7c10>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6c94d00>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea61d66a0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6861d30>,\n",
       " <pydub.audio_segment.AudioSegment at 0x20ea6861d60>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random pick start point\n",
    "# len(Audiosegment) 单位是时长毫秒\n",
    "# def get_one_noise(noise_num=0, duration=1000):\n",
    "#     selected_noise = background_noise[noise_num]\n",
    "#     start_idx = random.randint(0, len(selected_noise) - 1 - duration)\n",
    "#     return selected_noise[start_idx:(start_idx + duration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='speech_commands_v0.01\\\\weiqi\\\\sound0_noise0_0.wav'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将第一个围棋音频和第一个背景噪声进行混音并存储\n",
    "\n",
    "# sound = weiqi_audiosegment[0]\n",
    "# noise = get_one_noise(0, len(weiqi_audiosegment[0]))\n",
    "# # 把noise的音量降为sound音量的一半\n",
    "# noise = noise - ((1.5* abs(sound.dBFS))-abs(noise.dBFS))\n",
    "# combined = sound.overlay(noise)\n",
    "# combined.export(join(join(data_dir,'weiqi'),f'sound0_noise0_0.wav'), format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个文件生成200个带噪声的样本\n",
    "\n",
    "SAMPLE_NUM = 100\n",
    "\n",
    "for weiqi_num,_ in enumerate(weiqi_audiosegment):\n",
    "    for noise_num,_ in enumerate(background_noise):\n",
    "        sound = weiqi_audiosegment[weiqi_num]\n",
    "        for sn in range(SAMPLE_NUM):\n",
    "            duration = len(weiqi_audiosegment[weiqi_num])\n",
    "            selected_noise = background_noise[noise_num]\n",
    "            start_idx = random.randint(0, len(selected_noise) - 1 - duration)\n",
    "            noise = selected_noise[start_idx:(start_idx + duration)]\n",
    "            # 把noise的音量降为sound音量的一半\n",
    "            noise = noise - ((1.5* abs(sound.dBFS))-abs(noise.dBFS))\n",
    "            combined = sound.overlay(noise)\n",
    "            combined.export(join(join(data_dir,'weiqi'),f'sound{weiqi_num}_noise{noise_num}_{sn}.wav'), format=\"wav\")\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Speech Commands dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第1步：将所有的wav文件组成list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = [file for file in glob.glob(str(data_dir) + \"**/**/*.wav\", recursive=True) if '_background_noise_' not in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79535"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fileset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第2步：list导入到DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(fileset, columns=['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00176480_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path\n",
       "0  speech_commands_v0.01\\bed\\00176480_nohash_0.wav\n",
       "1  speech_commands_v0.01\\bed\\004ae714_nohash_0.wav\n",
       "2  speech_commands_v0.01\\bed\\004ae714_nohash_1.wav\n",
       "3  speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav\n",
       "4  speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第3步：将文件夹的名称提取作为指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['command'] = dataset['path'].apply(lambda x : os.path.basename(os.path.dirname(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>command</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00176480_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_1.wav</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path command\n",
       "0  speech_commands_v0.01\\bed\\00176480_nohash_0.wav     bed\n",
       "1  speech_commands_v0.01\\bed\\004ae714_nohash_0.wav     bed\n",
       "2  speech_commands_v0.01\\bed\\004ae714_nohash_1.wav     bed\n",
       "3  speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav     bed\n",
       "4  speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav     bed"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第4步：增加一列target_command，将不在target_command中的指令修改为unknown\n",
    "\n",
    "['weiqi', 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go',\n",
       "       'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on',\n",
       "       'one', 'right', 'seven', 'sheila', 'silence', 'six', 'stop',\n",
       "       'three', 'tree', 'two', 'up', 'weiqi', 'wow', 'yes', 'zero'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['command'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['weiqi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['target_command'] = np.where(dataset['command'].isin(target), dataset['command'], 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>command</th>\n",
       "      <th>target_command</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00176480_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_1.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path command target_command\n",
       "0  speech_commands_v0.01\\bed\\00176480_nohash_0.wav     bed        unknown\n",
       "1  speech_commands_v0.01\\bed\\004ae714_nohash_0.wav     bed        unknown\n",
       "2  speech_commands_v0.01\\bed\\004ae714_nohash_1.wav     bed        unknown\n",
       "3  speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav     bed        unknown\n",
       "4  speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav     bed        unknown"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unknown', 'weiqi'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target_command'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第4步：提取spectrum并写入dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算时频谱\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate /1e3))\n",
    "    freqs, times, spec = scipy.signal.spectrogram(audio, fs=sample_rate, window='hann', nperseg=nperseg, noverlap=noverlap, detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入文件的路径返回spectrogram\n",
    "\n",
    "def get_specgram(file_path):\n",
    "    sample_rate, signal= scipy.io.wavfile.read(file_path)\n",
    "    # 统一输入音频文件长度，当音频文件大于1秒时切尾，当音频长度小于1秒时补零\n",
    "    signal_padding = np.zeros((16000,))\n",
    "    if len(signal) >= 16000:\n",
    "        signal_padding = signal[:16000]\n",
    "    else:        \n",
    "        signal_padding[:len(signal)] = signal\n",
    "    # 获取频谱\n",
    "    _, _, specgram = log_specgram(signal_padding, sample_rate=sample_rate)\n",
    "\n",
    "    return specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\002706\\Anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\std.py:702: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c3aef9775144d1a7acd1814a69c516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "my bar!:   0%|          | 0/79535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"my bar!\")\n",
    "\n",
    "# 获取每个文件的spectrogram\n",
    "dataset['spec'] = dataset['path'].progress_apply(lambda x : get_specgram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用sklearn.preprocessing.LabelEncoder将指令转换为数字\n",
    "le_all = sk.preprocessing.LabelEncoder()\n",
    "\n",
    "# 增加新的一列all_cmd_value\n",
    "dataset['all_cmd_value'] = le_all.fit_transform(dataset['command'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>command</th>\n",
       "      <th>target_command</th>\n",
       "      <th>spec</th>\n",
       "      <th>all_cmd_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00176480_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[-6.2836647, -4.6634054, -3.6306102, -3.62951...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[5.674254, 5.0949345, -1.6267974, -2.909298, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_1.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[4.890464, 4.2362165, -0.52367973, -4.504811,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[0.2235076, -0.093135364, 1.7907851, 2.133407...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[-0.8384296, 0.48528323, 1.3839144, 0.5786768...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path command target_command  \\\n",
       "0  speech_commands_v0.01\\bed\\00176480_nohash_0.wav     bed        unknown   \n",
       "1  speech_commands_v0.01\\bed\\004ae714_nohash_0.wav     bed        unknown   \n",
       "2  speech_commands_v0.01\\bed\\004ae714_nohash_1.wav     bed        unknown   \n",
       "3  speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav     bed        unknown   \n",
       "4  speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav     bed        unknown   \n",
       "\n",
       "                                                spec  all_cmd_value  \n",
       "0  [[-6.2836647, -4.6634054, -3.6306102, -3.62951...              0  \n",
       "1  [[5.674254, 5.0949345, -1.6267974, -2.909298, ...              0  \n",
       "2  [[4.890464, 4.2362165, -0.52367973, -4.504811,...              0  \n",
       "3  [[0.2235076, -0.093135364, 1.7907851, 2.133407...              0  \n",
       "4  [[-0.8384296, 0.48528323, 1.3839144, 0.5786768...              0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加新的一列target_command的转换\n",
    "le_target = sk.preprocessing.LabelEncoder()\n",
    "dataset['target_cmd_value'] =  le_target.fit_transform(dataset['target_command'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['target_cmd_value_bool'] = dataset['target_command'].map({'unknown':0,'weiqi':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unknown'], dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_target.inverse_transform([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go',\n",
       "       'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on',\n",
       "       'one', 'right', 'seven', 'sheila', 'silence', 'six', 'stop',\n",
       "       'three', 'tree', 'two', 'up', 'weiqi', 'wow', 'yes', 'zero'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_all.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>command</th>\n",
       "      <th>target_command</th>\n",
       "      <th>spec</th>\n",
       "      <th>all_cmd_value</th>\n",
       "      <th>target_cmd_value_bool</th>\n",
       "      <th>target_cmd_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00176480_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[-6.2836647, -4.6634054, -3.6306102, -3.62951...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[5.674254, 5.0949345, -1.6267974, -2.909298, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speech_commands_v0.01\\bed\\004ae714_nohash_1.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[4.890464, 4.2362165, -0.52367973, -4.504811,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[0.2235076, -0.093135364, 1.7907851, 2.133407...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav</td>\n",
       "      <td>bed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[[-0.8384296, 0.48528323, 1.3839144, 0.5786768...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path command target_command  \\\n",
       "0  speech_commands_v0.01\\bed\\00176480_nohash_0.wav     bed        unknown   \n",
       "1  speech_commands_v0.01\\bed\\004ae714_nohash_0.wav     bed        unknown   \n",
       "2  speech_commands_v0.01\\bed\\004ae714_nohash_1.wav     bed        unknown   \n",
       "3  speech_commands_v0.01\\bed\\00f0204f_nohash_0.wav     bed        unknown   \n",
       "4  speech_commands_v0.01\\bed\\00f0204f_nohash_1.wav     bed        unknown   \n",
       "\n",
       "                                                spec  all_cmd_value  \\\n",
       "0  [[-6.2836647, -4.6634054, -3.6306102, -3.62951...              0   \n",
       "1  [[5.674254, 5.0949345, -1.6267974, -2.909298, ...              0   \n",
       "2  [[4.890464, 4.2362165, -0.52367973, -4.504811,...              0   \n",
       "3  [[0.2235076, -0.093135364, 1.7907851, 2.133407...              0   \n",
       "4  [[-0.8384296, 0.48528323, 1.3839144, 0.5786768...              0   \n",
       "\n",
       "   target_cmd_value_bool  target_cmd_value  \n",
       "0                      0                 0  \n",
       "1                      0                 0  \n",
       "2                      0                 0  \n",
       "3                      0                 0  \n",
       "4                      0                 0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D, LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model('best_model_part3_softmax.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 23, 256)           412416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 23, 128)           197120    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 750,530\n",
      "Trainable params: 750,018\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 23, 256)           412416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 23, 128)           197120    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 750,400\n",
      "Trainable params: 0\n",
      "Non-trainable params: 750,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (99, 161)\n",
    "\n",
    "inputs = Input(shape=input_dim)\n",
    "x = loaded_model(inputs, training=False)\n",
    "outputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 99, 161)]         0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 64)                750400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 750,465\n",
      "Trainable params: 65\n",
      "Non-trainable params: 750,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "sgd = SGD(lr=0.00001, clipnorm=1.0)\n",
    "adam = Adam(lr=1e-4, clipnorm=1.0)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=adam,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i for i in dataset['spec']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79535, 99, 161)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将目标指令转换为target_cmd_value\n",
    "y = np.array(dataset['target_cmd_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79535,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00001: val_accuracy improved from -inf to 1.00000, saving model to best_model_part3_sigmoid-retrain.h5\n",
      "995/995 [==============================] - 819s 823ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00002: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 816s 820ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00003: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 853s 857ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00004: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 839s 843ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00005: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 818s 822ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 815s 819ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 809s 813ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 813s 817ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 810s 815ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 809s 813ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00011: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 814s 818ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00012: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 816s 820ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00013: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 809s 813ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00014: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 814s 818ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 811s 815ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 810s 814ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 805s 809ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00018: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 805s 809ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 807s 811ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00020: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 809s 813ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00021: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 806s 810ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00022: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 802s 806ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00023: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 800s 804ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00024: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 807s 811ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00025: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 803s 807ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00026: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 802s 806ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00027: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 799s 803ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00028: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 809s 813ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00029: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 809s 813ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 806s 810ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 801s 806ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 802s 806ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 796s 800ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 810s 814ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 811s 816ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 807s 811ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00037: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 809s 813ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "995/995 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 1.00000\n",
      "995/995 [==============================] - 813s 817ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 00038: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[EarlyStopping(verbose=1, patience=3), \n",
    "               ModelCheckpoint('best_model_part3_sigmoid-retrain.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')],\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
